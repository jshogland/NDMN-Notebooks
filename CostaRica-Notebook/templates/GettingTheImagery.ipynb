{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the imagery from Google earth engine\n",
    "Google earth engine is a great resource for accessing and processing data. However, to facilitate everyone's processing workflows, Google limits the amount, types, and ways processing can occur. Moreover, to perform larger tasks on Google's servers can require purchasing additional resources. Alteratively, we can download base data and perform task off Google's services. In this notebook we will demonstrate how to stream intermediate products from Google's services for down stream analyses. Later we will use these data to estimate parameters of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import geopandas as gpd, pandas as pd, os, numpy as np\n",
    "import ee, geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate into Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize(project='ee-jshogland') #you will want to select your personal cloud project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create definitions for the median and medoid procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskL8sr(image):\n",
    "    # Bit 0 - Fill\n",
    "    # Bit 1 - Dilated Cloud\n",
    "    # Bit 2 - Cirrus\n",
    "    # Bit 3 - Cloud\n",
    "    # Bit 4 - Cloud Shadow\n",
    "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "    # Apply the scaling factors to the appropriate bands.\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "    #Replace the original bands with the scaled ones and apply the masks.\n",
    "    return image.addBands(opticalBands, overwrite=True).addBands(thermalBands, overwrite=True).updateMask(qaMask).updateMask(saturationMask)\n",
    "\n",
    "def median_mosaic(image,fltr=None,refl_bands=['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']):\n",
    "    if(fltr is None):\n",
    "        inCollection = image.filter(fltr).select(refl_bands)\n",
    "    else:\n",
    "        inCollection = image.filter(fltr).select(refl_bands)\n",
    "\n",
    "    return inCollection.median()\n",
    "\n",
    "def _medoid(col):\n",
    "    median = ee.ImageCollection(col).median()\n",
    "    diff=ee.Image(col).subtract(median).pow(ee.Image.constant(2))\n",
    "    return diff.reduce('sum').addBands(col)\n",
    "\n",
    "\n",
    "def medoid_mosaic(image, fltr,refl_bands=['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']):\n",
    "    if(fltr is None):\n",
    "        inCollection = image.filter(fltr).select(refl_bands)\n",
    "    else:\n",
    "        inCollection = image.filter(fltr).select(refl_bands)\n",
    "\n",
    "    medoid = inCollection.map(_medoid)\n",
    "    medoid = ee.ImageCollection(medoid).reduce(ee.Reducer.min(7)).select([1,2,3,4,5,6], refl_bands)\n",
    "    return medoid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set various variable and create the medoid surface on ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists fo band names for selections\n",
    "lc8_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'ST_B10', 'QA_PIXEL']#landsat band names\n",
    "tgt_bands = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP', 'QA_PIXEL']#common band names\n",
    "refl_bands = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']#bands we care about\n",
    "\n",
    "#specify start and end dates for the image filter\n",
    "startDate = '2021-01-01'\n",
    "endDate = '2024-07-01'\n",
    "\n",
    "#Specify julian dates for filter. Here we want to select sunny months\n",
    "julianStart1 = 350# Starting Julian Date (for landsat median cloud free )\n",
    "julianEnd1 = 365\n",
    "julianStart2 = 1\n",
    "julianEnd2 = 150# Ending Julian date (for landsat median cloud free)\n",
    "\n",
    "#define the study area extent from our convex hull\n",
    "#geo=geemap.gdf_to_ee(gpd.GeoDataFrame(geometry=chul)) #convert our convex hull into a ee feature class object\n",
    "\n",
    "#make the ee collection\n",
    "l8_col=ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "\n",
    "#set various filters\n",
    "#f_bnds=ee.Filter.bounds(geometry=geo)\n",
    "f_date=ee.Filter.date(startDate,endDate)\n",
    "f_cr1=ee.Filter.calendarRange(julianStart1,julianEnd1)\n",
    "f_cr2=ee.Filter.calendarRange(julianStart2,julianEnd2)\n",
    "f_or=ee.Filter.Or(f_cr1,f_cr2)\n",
    "f_and=ee.Filter.And(f_date,f_or)\n",
    "\n",
    "#use our filter on the landsat collection\n",
    "l8=l8_col.filter(f_and).map(maskL8sr)\n",
    "l8r=l8.select(lc8_bands,tgt_bands)\n",
    "\n",
    "#call the medoid function\n",
    "medoid = medoid_mosaic(l8r,fltr=f_and,refl_bands=refl_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create definitions to iteratively download imagery from Earth Engine\n",
    "This code is a little detailed and will send many requests to earth engine to accommodate their quota limits. Specifically, each chunk within the raster dataset will be a request for a image from Google earth image. So what are image chunks? Chunks are subsets of a large image that are used within Raster Tools to schedule processing. Each chunk is processed separately to accommodate parallel processing. In this case we are using dask and Raster Tools to parallelize the download of the medoid image from Google Earth image. When we save out the final image it will also get saved in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee, geopandas as gpd, dask, xarray as xr, numpy as np, io, requests,shapely\n",
    "from raster_tools import Raster, general\n",
    "\n",
    "def _convert_array2(x,bnds,rws,clms):\n",
    "    outarr=np.zeros((bnds,rws,clms),dtype='f8')\n",
    "    for r in range(x.shape[0]):\n",
    "        for c in range(x.shape[1]):\n",
    "            vls=x[r,c]\n",
    "            for b in range(bnds):\n",
    "                outarr[b,r,c]=vls[b]\n",
    "\n",
    "    return outarr\n",
    "\n",
    "def _get_block(ee_object,ee_geo,bnds,rws,clms):\n",
    "    success=True\n",
    "    url=ee_object.getDownloadURL({'format':'NPY','region':ee_geo})\n",
    "    try:\n",
    "        #print('downloading',url)\n",
    "        resp=requests.get(url)\n",
    "        data=np.load(io.BytesIO(resp.content))\n",
    "        #print('reformatting data')\n",
    "        outarr =_convert_array2(data,bnds,rws,clms)\n",
    "        #print('finished')\n",
    "    except Exception as e:\n",
    "        #print(e,url)\n",
    "        outarr=np.zeros((bnds,rws,clms))\n",
    "        success=False\n",
    "    finally:\n",
    "        return success,outarr,url\n",
    "\n",
    "def _get_block_values2(ee_object,xmin,ymax,res,oprj,retry=2,block_info=None):\n",
    "    bo_info=block_info[None]\n",
    "    aloc=bo_info['array-location']\n",
    "    bnds,rws,clms=bo_info['chunk-shape']\n",
    "    xrng=aloc[2]\n",
    "    yrng=aloc[1]\n",
    "    xmin2=xmin+(xrng[0]*res)\n",
    "    xmax2=xmin+(xrng[1]*res)\n",
    "    ymax2=ymax-(yrng[0]*res)\n",
    "    ymin2=ymax-(yrng[1]*res)\n",
    "    ply=[\n",
    "        [xmin2,ymin2],\n",
    "        [xmin2,ymax2],\n",
    "        [xmax2,ymax2],\n",
    "        [xmax2,ymin2],\n",
    "        [xmin2,ymin2]\n",
    "    ]\n",
    "    tbb=shapely.Polygon(ply)\n",
    "    tgdf=gpd.GeoSeries(tbb,crs=oprj).buffer(-res/2.0)\n",
    "    g=tgdf.to_crs('EPSG:4326').geometry.iloc[0]\n",
    "    xx,yy=g.exterior.coords.xy\n",
    "    x=list(xx)\n",
    "    y=list(yy)\n",
    "    ee_geo=ee.Geometry.Polygon(tuple(zip(x,y)))\n",
    "    cnt=0\n",
    "    success,outarr,url=_get_block(ee_object,ee_geo,bnds,rws,clms)\n",
    "    #build a loop to get data in the case of server error\n",
    "    while (success==False):\n",
    "        if(cnt>retry):\n",
    "            break\n",
    "        print('Retry',cnt+1)\n",
    "        success,outarr,url=_get_block(ee_object,ee_geo,bnds,rws,clms)\n",
    "        cnt+=1\n",
    "\n",
    "    if(success==False):\n",
    "        print(\"Problem with url\",url)\n",
    "\n",
    "    return outarr\n",
    "\n",
    "\n",
    "\n",
    "def get_raster(gdf, ee_object,dvs=2048):\n",
    "    '''\n",
    "    creates a raster dataset of specified resolution from point clouds\n",
    "\n",
    "    gdf: geodataframe from build_extent function\n",
    "    ee_object: earth engine image object\n",
    "    dvs: int of number of cells of the length of a square chunk\n",
    "\n",
    "    return: Raster of image values\n",
    "    '''\n",
    "    prj=ee_object.projection()\n",
    "    oprj=prj.crs().getInfo()\n",
    "    xmin,ymin,xmax,ymax=gdf.to_crs(oprj).total_bounds.astype('int32')\n",
    "    res=prj.nominalScale().getInfo()\n",
    "    xchs=int((xmax-xmin)/(dvs*res))+1\n",
    "    ychs=int((ymax-ymin)/(dvs*res))+1\n",
    "    xsteps=np.arange(xmin,xmin+(xchs*dvs*res),res)\n",
    "    ysteps=np.arange(ymax,ymax-(ychs*dvs*res),-res)\n",
    "\n",
    "\n",
    "    #make chunks\n",
    "    bnds = ee_object.bandNames().getInfo()\n",
    "\n",
    "    xchunk=tuple([dvs]*xchs)\n",
    "    ychunk=tuple([dvs]*ychs)\n",
    "\n",
    "    tda=dask.array.map_blocks(_get_block_values2,ee_object,xmin,ymax,res,oprj,chunks=((len(bnds)),ychunk,xchunk),dtype=float)\n",
    "    xrs=xr.DataArray(tda,coords={'band':bnds,'y':ysteps,'x':xsteps})\n",
    "    return xrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data!\n",
    "\n",
    "rs_medoid will just be a reference to the data but will give us the background info needed to make informed decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gpd.read_file('../Costa_Rica_Data/Classification_Plots.zip') #use the points to get the extent of the analysis area to download\n",
    "\n",
    "#get medoid images\n",
    "chul=gpd.GeoSeries(gdf.unary_union.convex_hull,crs=gdf.crs) #from the points create a boundary to use for downloading\n",
    "rs_medoid = get_raster(chul,medoid.setDefaultProjection(crs='EPSG:5367',scale=30),256) #note the projects we are setting on Google Earth Engine\n",
    "rs_medoid #show the xarray data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Understanding the procedure\n",
    "- How many cells are in the image?\n",
    "- How many bands are in the image?\n",
    "- How many processing chunks?\n",
    "- How many calls to Google Earth Engine will we be making to save out the entire image?\n",
    "- How many gb will the image take up?\n",
    "- If we were to download all the predictors sampled in the Costa Rica sample dataset, how many additional images would we need to download?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a subset of the image before downloading\n",
    "### let's subset the image to 6 chunks of size (1,1776,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=Raster(rs_medoid[:,10000:12048,10000:12048]).set_crs('EPSG:5367') #convert the xarray dataset into a Raster object\n",
    "rs.xdata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's process the requests and visualize the first 3 bands of the medoid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's time it with Dask's progress bar\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "  brs_m=rs.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.plot.imshow(brs_m.xdata[0:3,:,:],robust=True,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save the subset image to disk and plot each of the bands separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = 'medoid_subset.tif'\n",
    "if(not os.path.exists(outpath)):\n",
    "    brs_m.save('medoid_subset.tif')\n",
    "\n",
    "brs_m=Raster(outpath)\n",
    "brs_m.plot(x='x',y='y',col='band',col_wrap=3,figsize=(15,brs_m.nbands),cmap='PRGn',robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overlay band 1 on a interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brs_m.explore(band=1,robust=True,name='Medoid band 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise2: understanding the data 2\n",
    "- What proportion of the total image did we download and visualize?\n",
    "- How long did it take to download?\n",
    "- How many processors did we use to download the data?\n",
    "- Why did the subset image save to disk so fast when it took so long to load (what did the load function do)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's download the entire Medoid image\n",
    "This can take a while and will depend on your connection speed (~30 minutes on my computer). To get an idea of the total download time you can divide the processing time from loading the subset by the proportion of the total image we downloaded. This will roughly give you the time it takes to download the entire image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's time it with Dask's progress bar\n",
    "rs2=Raster(rs_medoid).set_crs('EPSG:5367') #convert xarray object to a Raster object\n",
    "with ProgressBar():\n",
    "  rs2.save('medoid.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Downloading Google Earth Engine images\n",
    "- Why are we downloading the Google Earth Engine images?\n",
    "- Download each of the images you plan to use in the modelling stage of your analyses. Do you need to download all images or can you recreate some images locally?\n",
    "- If two images provide identical information for your model, is it worth downloading both images?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
