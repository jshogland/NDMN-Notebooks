{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Feature Selection\n",
    "#### Creating a model and selecting features go hand in hand. The main objective here is to build a model with the least amount of error and the fewest number of parameters. While one approach to modeling might be to use every potential parameter to create the \"best possible model\", it is often the case that sample size, processing limitations, and data limitation make this approach unmanageable, prone to over fitting, and less than optimal. To combat these issues, we will be using an approach that takes into account model parsimony. The idea behind model parsimony is fairly simple and in concept adds a cost function to adding more features to a model (making a model more complex). If a given feature does not improve model accuracy beyond a specified amount, it is not worth adding that complexity to the model. This benefits the modeling process in multiple ways:\n",
    "- a less complex model\n",
    "- less processing\n",
    "- less download data\n",
    "- fewer sources of error\n",
    "- less over fitting\n",
    "- a model that can be generalized\n",
    "- fewer training samples\n",
    "- ...\n",
    "\n",
    "To demonstrate how to create a model we will be using the medeoid_subset.tif image and the plots_subplots that fall within the bounds of the extent of the medoid_subset.tif image. Before continuing, please make sure you have worked through [Summarizing plot data](./Summarizing_plot_data.ipynb) and [Getting The Imagery](./GettingTheImagery.ipynb) notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import raster tools\n",
    "from raster_tools import Raster, general\n",
    "import geopandas as gpd, shapely, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "#### Let's look at a red, green, blue rendering of the medoid image subset.\n",
    "Remember the mediod image has 6 bands (blue, green, red, nir, swir1, swir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medoid_sub_rs=Raster('medoid_subset.tif')\n",
    "rgb=medoid_sub_rs.get_bands([3,2,1]) #subset rearrange the bands so we get rgb\n",
    "rgb.xdata.plot.imshow(robust=True,figsize=(15,12)) #plot the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the plot_subplot dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the cleaned plots and subplots data\n",
    "plot_sub=pd.read_csv('plot_subplot_data.csv')\n",
    "\n",
    "#convert plot_sub to a geodataframe\n",
    "plot_sub=gpd.GeoDataFrame(plot_sub,geometry=gpd.GeoSeries.from_wkt(plot_sub['geometry']),crs=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the points to the boundary of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the boundary of the  image\n",
    "img_bnd=gpd.GeoSeries(shapely.box(*rgb.bounds),crs=rgb.crs)\n",
    "\n",
    "#get all points inside the boundary and just unique ids and geometry\n",
    "pint=plot_sub.loc[plot_sub.intersects(img_bnd.to_crs(plot_sub.crs).unary_union)].to_crs(rgb.crs)\n",
    " \n",
    "#explore the plot subplot\n",
    "pint.explore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Reading and displaying the data\n",
    "- How many plots and subplots?\n",
    "- What columns are response variables and predictor variables?\n",
    "- Where did the rest of the plots go?\n",
    "- Task1: add the image boundary to the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Use classification model\n",
    "### There are many potential modelling techniques we can use to estimate Use class labels. To demonstrate how to create competing models and select a parsimonious model we will use [multi-nominal logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and the overall accuracy statistic. T\n",
    "\n",
    "#### Get Response and Predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get resp and predictor variables\n",
    "resp='Use'\n",
    "pred=['BLUE','GREEN', 'NIR', 'RED', 'SWIR1', 'SWIR2', 'altura2', 'aspect',\n",
    "       'aspectcos', 'aspectdeg', 'aspectYesn', 'brightness', 'clay_1mMed',\n",
    "       'diff', 'elevation', 'evi', 'fpar', 'hand30_100', 'lai', 'mTPI', 'ndvi',\n",
    "       'ocs_1mMed', 'sand_1mMed', 'savi', 'Yeslt_1mMed', 'slope', 'topDiv',\n",
    "       'wetness']\n",
    "\n",
    "X=plot_sub[pred].values\n",
    "y=plot_sub[resp].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the predictor variables using a PCA and determine how many components are required to account for 95% of the total variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss=StandardScaler(with_mean=False) #scaling data without centering on the mean because PCA will center the data.\n",
    "ss.fit(X)\n",
    "X2=ss.transform(X) # scaling our values so they are comparable\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X2) # fit the PCA on scaled values\n",
    "vexp=pd.DataFrame(pca.explained_variance_ratio_,columns=['var']) # get the proportion of variance explained by each component\n",
    "\n",
    "#find the number of components needed to account for 95% of the variation in the data\n",
    "cmp=0\n",
    "s=0\n",
    "for v in vexp['var']:\n",
    "    s+=v\n",
    "    cmp+=1\n",
    "    if(s>0.95):break\n",
    "    \n",
    "#plot % covariance explained\n",
    "print('95% of the covariation can be explained using the first',cmp,'components')\n",
    "vexp.plot(kind='barh',figsize=(15,8),title='Percent variation by each component').invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform our predictors into independent components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get our components\n",
    "X3=pca.transform(X2) #what if we wanted to subset the components to the top 13? How would we do that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our first saturated multinominal logistic regression model and calculate overall accuracy.\n",
    "The overall accuracy is calculated as correctly labeled observations / total number of observations. For sake of parsimony, let's make a threshold based on overall model accuracy that stipulates, in order to add another parameter to our model, it must improve overall accuracy by 0.001%. Now we need to decide if we want to iteratively add parameters to our model (forward selection) using that rule or remove parameter from the model (backward selection). Let's start off using backward selection and remove parameters from a saturated model starting with the parameters that explain the least amount of variation in the data (remember our PCA results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create our saturated logistic regression model\n",
    "lg = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000) #increased the iteration so that the model can converge\n",
    "lg.fit(X3,y)\n",
    "\n",
    "# Get predicted probabilities of our training data\n",
    "# Logistic regression models actually estimate each category's probability of occurrence. Using those class probabilities we can label records using a set of rules.\n",
    "# By default, the predict function in sklearn's logistic class assigns class labels based on the most probable class (maximum likelihood class).\n",
    "\n",
    "#Let's calculate class accuracy\n",
    "pred_lbl=lg.predict(X3)\n",
    "print(\"% Overall accurate:\",accuracy_score(y,pred_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all components we get a overall accuracy of 0.713 for our training data. We can now use a backward selecting procedure to iteratively remove a given parameter and compare the accuracy achieved with a simpler model against the accuracy achieved with the more complex model. If the accuracy of the simpler model is within our threshold, then we can justify removing that parameter from our model. To do this let's convert our logistic regression procedure into a function that returns overall accuracy. In that way we can create a dataframe that quantifies the impact of each predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(X,y):\n",
    "    lg = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000) #increased the iteration so that the model can converge\n",
    "    lg.fit(X,y)\n",
    "    pred_lbl=lg.predict(X)\n",
    "    oa=accuracy_score(y,pred_lbl)\n",
    "    return oa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's use our function to remove predictors (backward selection) and quantify the impact on overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001 #to remove a parameter the difference in overall accuracy must be less than the threshold\n",
    "pca_df=pd.DataFrame(X3)\n",
    "df_clms=pca_df.columns\n",
    "pt_clms=df_clms.values\n",
    "oa=get_stats(pca_df.values,y)\n",
    "m_vls=[['_'.join(pt_clms.astype('str')),oa]]\n",
    "for i in range(df_clms.shape[0]-1,-1,-1): #count backwards to account for variation explained in principal components\n",
    "   clm=df_clms[i]\n",
    "   pt_clms2=np.delete(pt_clms,clm)\n",
    "   oa2=get_stats(pca_df[pt_clms2].values,y)\n",
    "   dif=oa-oa2 #subtract accuracies\n",
    "   if(dif>threshold):\n",
    "      pass\n",
    "   else:\n",
    "      pt_clms=pt_clms2\n",
    "      oa=oa2\n",
    "   m_vls.append([\"_\".join(pt_clms.astype('str')),oa])\n",
    "\n",
    "ac_df=pd.DataFrame(m_vls,columns=['param','oa'])\n",
    "\n",
    "print('Components used in the model',pt_clms)\n",
    "print('Overall accuracy', oa)\n",
    "display(ac_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001 #to remove a parameter the difference in overall accuracy must be less than the threshold\n",
    "pca_df=pd.DataFrame(X3)\n",
    "df_clms=pca_df.columns\n",
    "pt_clms=[]\n",
    "m_vls=[]\n",
    "oa=0\n",
    "for i in range(0,df_clms.shape[0]): #count forwards to account for variation explained in principal components\n",
    "   clm=df_clms[i]\n",
    "   pt_clms2 = pt_clms+[clm]\n",
    "   oa2=get_stats(pca_df[pt_clms2].values,y)\n",
    "   dif=oa2-oa #subtract accuracies\n",
    "   if(dif>threshold):\n",
    "      pt_clms=pt_clms2\n",
    "      oa=oa2\n",
    "   m_vls.append([\"_\".join(np.array(pt_clms).astype('str')),oa])\n",
    "\n",
    "ac_df=pd.DataFrame(m_vls,columns=['param','oa'])\n",
    "\n",
    "print('Components used in the model',pt_clms)\n",
    "print('Overall accuracy', oa)\n",
    "display(ac_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Feature Selection\n",
    "- Why didn't we just select the first 13 components as our predictors? \n",
    "- What features were selected for the backward and forward selection routines?\n",
    "- Did backward or forward selection produce better results?\n",
    "- What happens if you increase the threshold?\n",
    "- Can you think of a way to combine forward and backward selection methods?\n",
    "- Task 1: What accuracy do you get using the first 13 components as parameters in the model?\n",
    "- Task 2: Use class probabilities (predict_proba) to estimate the total number of observation in each class. Compare that to the labeled estimate of the number of observations in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sklearn's feature selection\n",
    "### Sklearn also has a few built in feature selection routines ([link](https://scikit-learn.org/stable/modules/feature_selection.html)). To demonstrate we will use the L2 feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "df=pd.DataFrame(X3)\n",
    "\n",
    "lg = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000,penalty='l2') \n",
    "lg.fit(df,y)\n",
    "model = SelectFromModel(lg, prefit=True)\n",
    "X_new = model.transform(df)\n",
    "\n",
    "#find components selected\n",
    "fr=X_new[0]\n",
    "frdf=df.iloc[0,:]\n",
    "scmp=[]\n",
    "for v in fr:\n",
    "    cnt=0\n",
    "    for v2 in frdf:\n",
    "        if(v==v2):\n",
    "            scmp.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "\n",
    "print('Components selected',scmp)\n",
    "print('Overall accuracy',get_stats(X_new,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: sklearn's l2 feature selection\n",
    "- How many features (components) were selected?\n",
    "- Is model accuracy better or worse?\n",
    "- What is being selected for using this method? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
